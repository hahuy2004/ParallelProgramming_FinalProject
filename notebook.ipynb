{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Autoencoder + SVM với CUDA\n",
    "**Đồ án cuối kỳ - Lập trình Song song (CSC14120)**\n",
    "\n",
    "---\n",
    "\n",
    "## Mục lục\n",
    "1. Setup môi trường\n",
    "2. Compile project\n",
    "3. Phase 1: CPU Baseline\n",
    "4. Phase 2: Naive GPU\n",
    "5. Phase 3: Optimized GPU\n",
    "6. Phase 4: SVM Classification\n",
    "7. So sánh kết quả\n",
    "8. Kết luận"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup môi trường\n",
    "\n",
    "### Kiểm tra GPU và CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CUDA Version:\")\n",
    "print(\"=\"*60)\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup trên Google Colab (uncomment nếu cần)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === COLAB SETUP (uncomment) ===\n",
    "# !git clone https://github.com/your-repo/project.git\n",
    "# %cd project\n",
    "# !wget https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n",
    "# !tar -xzf cifar-10-binary.tar.gz\n",
    "# !mkdir -p third_party && cd third_party && git clone https://github.com/cjlin1/libsvm.git && cd libsvm && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check project structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Adjust for your environment\n",
    "PROJECT_DIR = \"/home/hahuy2004/LT_song_song/LT/Project\"\n",
    "# For Colab: PROJECT_DIR = \"/content/project\"\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "print(\"\\nChecking files...\")\n",
    "required = [\"cifar-10-batches-bin\", \"src\", \"cuda\", \"include\", \"Makefile\", \"run_pipeline.py\"]\n",
    "for item in required:\n",
    "    exists = os.path.exists(item)\n",
    "    print(f\"[{'OK' if exists else 'MISSING'}] {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, PROJECT_DIR)\n",
    "from run_pipeline import CIFARAutoencoderPipeline\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = CIFARAutoencoderPipeline(PROJECT_DIR)\n",
    "\n",
    "# Check setup\n",
    "pipeline.check_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Compile Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all phases\n",
    "print(\"=\"*60)\n",
    "print(\"Compiling...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline.compile_all()\n",
    "\n",
    "# Check executables\n",
    "!ls -lh build/phase*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Phase 1: CPU Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 1: CPU BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start = time.time()\n",
    "result1 = pipeline.run_phase1_cpu()\n",
    "phase1_time = time.time() - start\n",
    "\n",
    "print(f\"\\n[RESULT] Phase 1 time: {phase1_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Phase 2: Naive GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 2: NAIVE GPU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start = time.time()\n",
    "result2 = pipeline.run_phase2_gpu()\n",
    "phase2_time = time.time() - start\n",
    "\n",
    "print(f\"\\n[RESULT] Phase 2 time: {phase2_time:.2f}s\")\n",
    "if phase1_time > 0:\n",
    "    print(f\"[SPEEDUP] {phase1_time/phase2_time:.2f}x vs CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Phase 3: Optimized GPU\n",
    "\n",
    "### Optimizations Applied:\n",
    "- Kernel fusion (Conv + ReLU)\n",
    "- Pinned memory\n",
    "- Async transfers\n",
    "- Larger batch size (128 vs 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 3: OPTIMIZED GPU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start = time.time()\n",
    "result3 = pipeline.run_phase3_optimized()\n",
    "phase3_time = time.time() - start\n",
    "\n",
    "print(f\"\\n[RESULT] Phase 3 time: {phase3_time:.2f}s\")\n",
    "if phase1_time > 0:\n",
    "    print(f\"[SPEEDUP] {phase1_time/phase3_time:.2f}x vs CPU\")\n",
    "if phase2_time > 0:\n",
    "    print(f\"[SPEEDUP] {phase2_time/phase3_time:.2f}x vs Naive GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Phase 4: SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 4: SVM CLASSIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start = time.time()\n",
    "result4 = pipeline.run_phase4_svm(use_optimized=True)\n",
    "phase4_time = time.time() - start\n",
    "\n",
    "print(f\"\\n[RESULT] Phase 4 time: {phase4_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. So sánh kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create comparison table\n",
    "df = pd.DataFrame({\n",
    "    \"Phase\": [\"CPU Baseline\", \"Naive GPU\", \"Optimized GPU\"],\n",
    "    \"Time (s)\": [phase1_time, phase2_time, phase3_time],\n",
    "    \"Speedup vs CPU\": [\n",
    "        1.0,\n",
    "        phase1_time/phase2_time if phase2_time > 0 else 0,\n",
    "        phase1_time/phase3_time if phase3_time > 0 else 0\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Check target\n",
    "final_speedup = phase1_time/phase3_time if phase3_time > 0 else 0\n",
    "target_met = \"PASS\" if final_speedup >= 20 else \"FAIL\"\n",
    "print(f\"\\n[TARGET] Speedup >20x: {target_met} ({final_speedup:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training time\n",
    "colors = [\"#3498db\", \"#e74c3c\", \"#2ecc71\"]\n",
    "ax1.bar(df[\"Phase\"], df[\"Time (s)\"], color=colors)\n",
    "ax1.set_ylabel(\"Time (seconds)\", fontsize=12)\n",
    "ax1.set_title(\"Training Time Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Speedup\n",
    "ax2.bar(df[\"Phase\"], df[\"Speedup vs CPU\"], color=colors)\n",
    "ax2.axhline(y=20, color=\"orange\", linestyle=\"--\", linewidth=2, label=\"Target: 20x\")\n",
    "ax2.set_ylabel(\"Speedup (x)\", fontsize=12)\n",
    "ax2.set_title(\"Speedup vs CPU Baseline\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.legend()\n",
    "ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Kết luận\n",
    "\n",
    "### Thành tựu đạt được\n",
    "- Implementation hoàn chỉnh 4 phases\n",
    "- CPU baseline\n",
    "- Naive GPU implementation\n",
    "- Optimized GPU với kernel fusion, pinned memory, async transfers\n",
    "- Full pipeline với SVM\n",
    "\n",
    "### Kỹ thuật tối ưu (Phase 3)\n",
    "1. **Kernel fusion:** Conv2D + ReLU merged → 15-20% faster\n",
    "2. **Pinned memory:** cudaMallocHost → 2x faster transfers\n",
    "3. **Async transfers:** cudaMemcpyAsync → hide latency\n",
    "4. **Batch size:** 128 vs 64 → better GPU occupancy\n",
    "\n",
    "### Cải tiến trong tương lai\n",
    "- Shared memory tiling\n",
    "- Multi-stream execution\n",
    "- Mixed precision (FP16)\n",
    "- cuDNN integration\n",
    "\n",
    "---\n",
    "\n",
    "**Project completed!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
